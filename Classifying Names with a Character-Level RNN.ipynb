{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names/Czech.txt', 'data/names/German.txt', 'data/names/Arabic.txt', 'data/names/Japanese.txt', 'data/names/Chinese.txt', 'data/names/Vietnamese.txt', 'data/names/Russian.txt', 'data/names/French.txt', 'data/names/Irish.txt', 'data/names/English.txt', 'data/names/Spanish.txt', 'data/names/Greek.txt', 'data/names/Italian.txt', 'data/names/Portuguese.txt', 'data/names/Scottish.txt', 'data/names/Dutch.txt', 'data/names/Korean.txt', 'data/names/Polish.txt']\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Czech',\n",
       " 'German',\n",
       " 'Arabic',\n",
       " 'Japanese',\n",
       " 'Chinese',\n",
       " 'Vietnamese',\n",
       " 'Russian',\n",
       " 'French',\n",
       " 'Irish',\n",
       " 'English',\n",
       " 'Spanish',\n",
       " 'Greek',\n",
       " 'Italian',\n",
       " 'Portuguese',\n",
       " 'Scottish',\n",
       " 'Dutch',\n",
       " 'Korean',\n",
       " 'Polish']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abl',\n",
       " 'Adsit',\n",
       " 'Ajdrna',\n",
       " 'Alt',\n",
       " 'Antonowitsch',\n",
       " 'Antonowitz',\n",
       " 'Bacon',\n",
       " 'Ballalatak',\n",
       " 'Ballaltick',\n",
       " 'Bartonova',\n",
       " 'Bastl',\n",
       " 'Baroch',\n",
       " 'Benesch',\n",
       " 'Betlach',\n",
       " 'Biganska',\n",
       " 'Bilek',\n",
       " 'Blahut',\n",
       " 'Blazek',\n",
       " 'Blazek',\n",
       " 'Blazejovsky',\n",
       " 'Blecha',\n",
       " 'Bleskan',\n",
       " 'Blober',\n",
       " 'Bock',\n",
       " 'Bohac',\n",
       " 'Bohunovsky',\n",
       " 'Bolcar',\n",
       " 'Borovka',\n",
       " 'Borovski',\n",
       " 'Borowski',\n",
       " 'Borovsky',\n",
       " 'Brabbery',\n",
       " 'Brezovjak',\n",
       " 'Brousil',\n",
       " 'Bruckner',\n",
       " 'Buchta',\n",
       " 'Cablikova',\n",
       " 'Camfrlova',\n",
       " 'Cap',\n",
       " 'Cerda',\n",
       " 'Cermak',\n",
       " 'Chermak',\n",
       " 'Cermak',\n",
       " 'Cernochova',\n",
       " 'Cernohous',\n",
       " 'Cerny',\n",
       " 'Cerney',\n",
       " 'Cerny',\n",
       " 'Cerv',\n",
       " 'Cervenka',\n",
       " 'Chalupka',\n",
       " 'Charlott',\n",
       " 'Chemlik',\n",
       " 'Chicken',\n",
       " 'Chilar',\n",
       " 'Chromy',\n",
       " 'Cihak',\n",
       " 'Clineburg',\n",
       " 'Klineberg',\n",
       " 'Cober',\n",
       " 'Colling',\n",
       " 'Cvacek',\n",
       " 'Czabal',\n",
       " 'Damell',\n",
       " 'Demall',\n",
       " 'Dehmel',\n",
       " 'Dana',\n",
       " 'Dejmal',\n",
       " 'Dempko',\n",
       " 'Demko',\n",
       " 'Dinko',\n",
       " 'Divoky',\n",
       " 'Dolejsi',\n",
       " 'Dolezal',\n",
       " 'Doljs',\n",
       " 'Dopita',\n",
       " 'Drassal',\n",
       " 'Driml',\n",
       " 'Duyava',\n",
       " 'Dvorak',\n",
       " 'Dziadik',\n",
       " 'Egr',\n",
       " 'Entler',\n",
       " 'Faltysek',\n",
       " 'Faltejsek',\n",
       " 'Fencl',\n",
       " 'Fenyo',\n",
       " 'Fillipova',\n",
       " 'Finfera',\n",
       " 'Finferovy',\n",
       " 'Finke',\n",
       " 'Fojtikova',\n",
       " 'Fremut',\n",
       " 'Friedrich',\n",
       " 'Frierdich',\n",
       " 'Fritsch',\n",
       " 'Furtsch',\n",
       " 'Gabrisova',\n",
       " 'Gavalok',\n",
       " 'Geier',\n",
       " 'Georgijev',\n",
       " 'Geryk',\n",
       " 'Giersig',\n",
       " 'Glatter',\n",
       " 'Glockl',\n",
       " 'Grabski',\n",
       " 'Grozmanova',\n",
       " 'Grulich',\n",
       " 'Grygarova',\n",
       " 'Hadash',\n",
       " 'Hafernik',\n",
       " 'Hajek',\n",
       " 'Hajicek',\n",
       " 'Hajkova',\n",
       " 'Hana',\n",
       " 'Hanek',\n",
       " 'Hanek',\n",
       " 'Hanika',\n",
       " 'Hanusch',\n",
       " 'Hanzlick',\n",
       " 'Handzlik',\n",
       " 'Hanzlik',\n",
       " 'Harger',\n",
       " 'Hartl',\n",
       " 'Havlatova',\n",
       " 'Havlice',\n",
       " 'Hawlata',\n",
       " 'Heidl',\n",
       " 'Herback',\n",
       " 'Herodes',\n",
       " 'Hiorvst',\n",
       " 'Hladky',\n",
       " 'Hlavsa',\n",
       " 'Hnizdil',\n",
       " 'Hodowal',\n",
       " 'Hodoval',\n",
       " 'Holan',\n",
       " 'Holub',\n",
       " 'Homulka',\n",
       " 'Hora',\n",
       " 'Hovanec',\n",
       " 'Hrabak',\n",
       " 'Hradek',\n",
       " 'Hrdy',\n",
       " 'Hrula',\n",
       " 'Hruska',\n",
       " 'Hruskova',\n",
       " 'Hudecek',\n",
       " 'Husk',\n",
       " 'Hynna',\n",
       " 'Jaluvka',\n",
       " 'Janca',\n",
       " 'Janicek',\n",
       " 'Jenicek',\n",
       " 'Janacek',\n",
       " 'Janick',\n",
       " 'Janoch',\n",
       " 'Janosik',\n",
       " 'Janutka',\n",
       " 'Jares',\n",
       " 'Jarzembowski',\n",
       " 'Jedlicka',\n",
       " 'Jelinek',\n",
       " 'Jindra',\n",
       " 'Jirava',\n",
       " 'Jirik',\n",
       " 'Jirku',\n",
       " 'Jirovy',\n",
       " 'Jobst',\n",
       " 'Jonas',\n",
       " 'Kacirek',\n",
       " 'Kafka',\n",
       " 'Kafka',\n",
       " 'Kaiser',\n",
       " 'Kanak',\n",
       " 'Kaplanek',\n",
       " 'Kara',\n",
       " 'Karlovsky',\n",
       " 'Kasa',\n",
       " 'Kasimor',\n",
       " 'Kazimor',\n",
       " 'Kazmier',\n",
       " 'Katschker',\n",
       " 'Kauphsman',\n",
       " 'Kenzel',\n",
       " 'Kerner',\n",
       " 'Kesl',\n",
       " 'Kessel',\n",
       " 'Kessler',\n",
       " 'Khork',\n",
       " 'Kirchma',\n",
       " 'Klein',\n",
       " 'Klemper',\n",
       " 'Klimes',\n",
       " 'Kober',\n",
       " 'Koberna',\n",
       " 'Koci',\n",
       " 'Kocian',\n",
       " 'Kocian',\n",
       " 'Kofron',\n",
       " 'Kolacny',\n",
       " 'Koliha',\n",
       " 'Kolman',\n",
       " 'Koma',\n",
       " 'Komo',\n",
       " 'Coma',\n",
       " 'Konarik',\n",
       " 'Kopp',\n",
       " 'Kopecky',\n",
       " 'Korandak',\n",
       " 'Korycan',\n",
       " 'Korycansky',\n",
       " 'Kosko',\n",
       " 'Kouba',\n",
       " 'Kouba',\n",
       " 'Koukal',\n",
       " 'Koza',\n",
       " 'Kozumplikova',\n",
       " 'Kratschmar',\n",
       " 'Krawiec',\n",
       " 'Kreisinger',\n",
       " 'Kremlacek',\n",
       " 'Kremlicka',\n",
       " 'Kreutschmer',\n",
       " 'Krhovsky',\n",
       " 'Krivan',\n",
       " 'Krivolavy',\n",
       " 'Kriz',\n",
       " 'Kruessel',\n",
       " 'Krupala',\n",
       " 'Krytinar',\n",
       " 'Kubin',\n",
       " 'Kucera',\n",
       " 'Kucharova',\n",
       " 'Kudrna',\n",
       " 'Kuffel',\n",
       " 'Kupfel',\n",
       " 'Kofel',\n",
       " 'Kulhanek',\n",
       " 'Kunik',\n",
       " 'Kurtz',\n",
       " 'Kusak',\n",
       " 'Kvasnicka',\n",
       " 'Lawa',\n",
       " 'Linart',\n",
       " 'Lind',\n",
       " 'Lokay',\n",
       " 'Loskot',\n",
       " 'Ludwig',\n",
       " 'Lynsmeier',\n",
       " 'Macha',\n",
       " 'Machacek',\n",
       " 'Macikova',\n",
       " 'Malafa',\n",
       " 'Malec',\n",
       " 'Malecha',\n",
       " 'Maly',\n",
       " 'Marek',\n",
       " 'Marik',\n",
       " 'Marik',\n",
       " 'Markytan',\n",
       " 'Matejka',\n",
       " 'Matjeka',\n",
       " 'Matocha',\n",
       " 'MaxaB',\n",
       " 'Mayer',\n",
       " 'Meier',\n",
       " 'Merta',\n",
       " 'Meszes',\n",
       " 'Metjeka',\n",
       " 'Michalovic',\n",
       " 'Michalovicova',\n",
       " 'Miksatkova',\n",
       " 'Mojzis',\n",
       " 'Mojjis',\n",
       " 'Mozzis',\n",
       " 'Molcan',\n",
       " 'Monfort',\n",
       " 'MonkoAustria',\n",
       " 'Morava',\n",
       " 'Morek',\n",
       " 'Muchalon',\n",
       " 'Mudra',\n",
       " 'Muhlbauer',\n",
       " 'Nadvornizch',\n",
       " 'Nadwornik',\n",
       " 'Navara',\n",
       " 'Navratil',\n",
       " 'Navratil',\n",
       " 'Navrkal',\n",
       " 'Nekuza',\n",
       " 'Nemec',\n",
       " 'Nemecek',\n",
       " 'Nestrojil',\n",
       " 'Netsch',\n",
       " 'Neusser',\n",
       " 'Neisser',\n",
       " 'Naizer',\n",
       " 'Novak',\n",
       " 'Nowak',\n",
       " 'Novotny',\n",
       " 'Novy Novy',\n",
       " 'Oborny',\n",
       " 'Ocasek',\n",
       " 'Ocaskova',\n",
       " 'Oesterreicher',\n",
       " 'Okenfuss',\n",
       " 'Olbrich',\n",
       " 'Ondrisek',\n",
       " 'Opizka',\n",
       " 'Opova',\n",
       " 'Opp',\n",
       " 'Osladil',\n",
       " 'Ozimuk',\n",
       " 'Pachr',\n",
       " 'Palzewicz',\n",
       " 'Panek',\n",
       " 'Patril',\n",
       " 'Pavlik',\n",
       " 'Pavlicka',\n",
       " 'Pavlu',\n",
       " 'Pawlak',\n",
       " 'Pear',\n",
       " 'Peary',\n",
       " 'Pech',\n",
       " 'Peisar',\n",
       " 'Paisar',\n",
       " 'Paiser',\n",
       " 'Perevuznik',\n",
       " 'Perina',\n",
       " 'Persein',\n",
       " 'Petrezelka',\n",
       " 'Petru',\n",
       " 'Pesek',\n",
       " 'Petersen',\n",
       " 'Pfeifer',\n",
       " 'Picha',\n",
       " 'Pillar',\n",
       " 'Pellar',\n",
       " 'Piller',\n",
       " 'Pinter',\n",
       " 'Pitterman',\n",
       " 'Planick',\n",
       " 'Piskach',\n",
       " 'Plisek',\n",
       " 'Plisko',\n",
       " 'Pokorny',\n",
       " 'Ponec',\n",
       " 'Ponec',\n",
       " 'Prachar',\n",
       " 'Praseta',\n",
       " 'Prchal',\n",
       " 'Prehatney',\n",
       " 'Pretsch',\n",
       " 'Prill',\n",
       " 'Psik',\n",
       " 'Pudel',\n",
       " 'Purdes',\n",
       " 'Quasninsky',\n",
       " 'Raffel',\n",
       " 'Rafaj',\n",
       " 'Ransom',\n",
       " 'Rezac',\n",
       " 'Riedel',\n",
       " 'Riha',\n",
       " 'Riha',\n",
       " 'Ritchie',\n",
       " 'Rozinek',\n",
       " 'Ruba',\n",
       " 'Ruda',\n",
       " 'Rumisek',\n",
       " 'Ruzicka',\n",
       " 'Rypka',\n",
       " 'Rebka',\n",
       " 'Rzehak',\n",
       " 'Sabol',\n",
       " 'Safko',\n",
       " 'Samz',\n",
       " 'Sankovsky',\n",
       " 'Sappe',\n",
       " 'Sappe',\n",
       " 'Sarna',\n",
       " 'Satorie',\n",
       " 'Savchak',\n",
       " 'Svotak',\n",
       " 'Swatchak',\n",
       " 'Svocak',\n",
       " 'Svotchak',\n",
       " 'Schallom',\n",
       " 'Schenk',\n",
       " 'Schlantz',\n",
       " 'Schmeiser',\n",
       " 'Schneider',\n",
       " 'Schmied',\n",
       " 'Schubert',\n",
       " 'Schwarz',\n",
       " 'Schwartz',\n",
       " 'Sedmik',\n",
       " 'Sedmikova',\n",
       " 'Seger',\n",
       " 'Sekovora',\n",
       " 'Semick',\n",
       " 'Serak',\n",
       " 'Sherak',\n",
       " 'Shima',\n",
       " 'Shula',\n",
       " 'Siegl',\n",
       " 'Silhan',\n",
       " 'Simecek',\n",
       " 'Simodines',\n",
       " 'Simonek',\n",
       " 'Sip',\n",
       " 'Sitta',\n",
       " 'Skala',\n",
       " 'Skeril',\n",
       " 'Skokan',\n",
       " 'Skomicka',\n",
       " 'Skwor',\n",
       " 'Slapnickova',\n",
       " 'Slejtr',\n",
       " 'Slepicka',\n",
       " 'Slepica',\n",
       " 'Slezak',\n",
       " 'Slivka',\n",
       " 'Smith',\n",
       " 'Snelker',\n",
       " 'Sokolik',\n",
       " 'Soucek',\n",
       " 'Soukup',\n",
       " 'Soukup',\n",
       " 'Spicka',\n",
       " 'Spoerl',\n",
       " 'Sponer',\n",
       " 'Srda',\n",
       " 'Srpcikova',\n",
       " 'Stangl',\n",
       " 'Stanzel',\n",
       " 'Stary',\n",
       " 'Staska',\n",
       " 'Stedronsky',\n",
       " 'Stegon',\n",
       " 'Sztegon',\n",
       " 'Steinborn',\n",
       " 'Stepan',\n",
       " 'Stites',\n",
       " 'Stluka',\n",
       " 'Stotzky',\n",
       " 'StrakaO',\n",
       " 'Stramba',\n",
       " 'Stupka',\n",
       " 'Subertova',\n",
       " 'Suchanka',\n",
       " 'Sula',\n",
       " 'Svejda',\n",
       " 'Svejkovsky',\n",
       " 'Svoboda',\n",
       " 'Tejc',\n",
       " 'Tikal',\n",
       " 'Tykal',\n",
       " 'Till',\n",
       " 'Timpe',\n",
       " 'Timpy',\n",
       " 'Toman',\n",
       " 'Tomanek',\n",
       " 'Tomasek',\n",
       " 'Tomes',\n",
       " 'Trampotova',\n",
       " 'Trampota',\n",
       " 'Treblik',\n",
       " 'Trnkova',\n",
       " 'Uerling',\n",
       " 'Uhlik',\n",
       " 'Urbanek',\n",
       " 'Urbanek',\n",
       " 'Urbanovska',\n",
       " 'Urista',\n",
       " 'Ustohal',\n",
       " 'Vaca',\n",
       " 'Vaculova',\n",
       " 'Vavra',\n",
       " 'Vejvoda',\n",
       " 'Veverka',\n",
       " 'Victor',\n",
       " 'Vlach',\n",
       " 'Vlach',\n",
       " 'Vlasak',\n",
       " 'Vlasek',\n",
       " 'Volcik',\n",
       " 'Voneve',\n",
       " 'Votke',\n",
       " 'Vozab',\n",
       " 'Vrazel',\n",
       " 'Vykruta',\n",
       " 'Wykruta',\n",
       " 'Waclauska',\n",
       " 'Weichert',\n",
       " 'Weineltk',\n",
       " 'Weisener',\n",
       " 'Wiesner',\n",
       " 'Wizner',\n",
       " 'Weiss',\n",
       " 'Werlla',\n",
       " 'Whitmire',\n",
       " 'Widerlechner',\n",
       " 'Wilchek',\n",
       " 'Wondracek',\n",
       " 'Wood',\n",
       " 'Zajicek',\n",
       " 'Zak',\n",
       " 'Zajicek',\n",
       " 'Zaruba',\n",
       " 'Zaruba',\n",
       " 'Zelinka',\n",
       " 'Zeman',\n",
       " 'Zimola',\n",
       " 'Zipperer',\n",
       " 'Zitka',\n",
       " 'Zoucha',\n",
       " 'Zwolenksy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_lines['Czech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 26 to 38 \n",
      "    0     0     0     0     0     0     0     0     0     1     0     0     0\n",
      "\n",
      "Columns 39 to 51 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 52 to 56 \n",
      "    0     0     0     0     0\n",
      "[torch.FloatTensor of size 1x57]\n",
      "\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-2.8980 -3.0456 -2.8910 -2.8496 -2.8043 -2.9891 -2.9457 -2.8158 -2.8486 -2.8312\n",
      "\n",
      "Columns 10 to 17 \n",
      "-2.9021 -2.8805 -2.8748 -2.8604 -2.8268 -2.9190 -2.9150 -2.9632\n",
      "[torch.FloatTensor of size 1x18]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(lineToTensor('Albert'))\n",
    "hidden = Variable(torch.zeros(1, n_hidden))\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Scottish / line = Cunningham\n",
      "category = Korean / line = Rheem\n",
      "category = French / line = Boucher\n",
      "category = Spanish / line = Rodriguez\n",
      "category = Italian / line = Franzese\n",
      "category = Portuguese / line = Araullo\n",
      "category = Korean / line = Choi\n",
      "category = German / line = Worner\n",
      "category = Japanese / line = Minatoya\n",
      "category = English / line = Blackwell\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
    "    line_tensor = Variable(lineToTensor(line))\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (0m 3s) 2.7563 Rademakers / Greek ✗ (Dutch)\n",
      "10000 10% (0m 7s) 3.7581 Hay / Chinese ✗ (Scottish)\n",
      "15000 15% (0m 11s) 1.9887 Favre / French ✓\n",
      "20000 20% (0m 14s) 1.2311 Srour / Arabic ✓\n",
      "25000 25% (0m 18s) 0.4511 Snyders / Dutch ✓\n",
      "30000 30% (0m 22s) 1.2200 Mckay / Scottish ✓\n",
      "35000 35% (0m 25s) 1.3520 Janick / Czech ✓\n",
      "40000 40% (0m 29s) 2.5827 Flynn / Scottish ✗ (Irish)\n",
      "45000 45% (0m 33s) 2.6357 Stamp / Arabic ✗ (English)\n",
      "50000 50% (0m 36s) 1.3493 Yun / Chinese ✗ (Korean)\n",
      "55000 55% (0m 40s) 2.7112 Prill / English ✗ (Czech)\n",
      "60000 60% (0m 44s) 2.2078 Said / Korean ✗ (Arabic)\n",
      "65000 65% (0m 47s) 3.4021 StrakaO / Arabic ✗ (Czech)\n",
      "70000 70% (0m 51s) 2.5285 Hall / Scottish ✗ (German)\n",
      "75000 75% (0m 55s) 2.2128 Hase / Japanese ✗ (German)\n",
      "80000 80% (0m 58s) 0.4362 Henriques / Portuguese ✓\n",
      "85000 85% (1m 2s) 0.0656 Cathain / Irish ✓\n",
      "90000 90% (1m 6s) 0.7203 D'cruze / Portuguese ✓\n",
      "95000 95% (1m 9s) 2.6893 Wizner / Polish ✗ (Czech)\n",
      "100000 100% (1m 13s) 2.4736 Bell / German ✗ (Scottish)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n",
    "    category_i = top_i[0][0]\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
